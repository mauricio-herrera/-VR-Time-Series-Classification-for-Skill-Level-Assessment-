{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daf1abc0-5bc7-48b8-b393-09bc4e65b36f",
   "metadata": {},
   "source": [
    "# Data Loading and Class Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e3fab06-3ce8-4ea8-9ca5-75bbc5fd3b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert and novice data loaded.\n",
      "Total time series: 14\n",
      "Data example:                  Timestamp  PositionX  PositionY  PositionZ  RotationX  \\\n",
      "0  2023-05-17 15:12:37.254   0.066467  -0.148628   0.171193   0.126154   \n",
      "1  2023-05-17 15:12:37.263   0.099649  -0.153283   0.165442   0.031201   \n",
      "2  2023-05-17 15:12:37.269   0.099649  -0.153283   0.165442   0.031201   \n",
      "3  2023-05-17 15:12:37.274   0.099649  -0.153283   0.165442   0.031201   \n",
      "4  2023-05-17 15:12:37.317   0.099225  -0.153320   0.165391   0.032077   \n",
      "\n",
      "   RotationY  RotationZ  RotationW   label  \n",
      "0   0.984342  -0.056134  -0.109569  expert  \n",
      "1   0.998373  -0.041187  -0.024101  expert  \n",
      "2   0.998373  -0.041187  -0.024101  expert  \n",
      "3   0.998373  -0.041187  -0.024101  expert  \n",
      "4   0.998298  -0.041397  -0.025646  expert  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Data directories\n",
    "expert_dir = './trajectories/expert'\n",
    "novice_dir = './trajectories/novice'\n",
    "\n",
    "# Function to load data and label\n",
    "def load_data(directory, label):\n",
    "    data_list = []\n",
    "    for filepath in glob.glob(os.path.join(directory, \"*.csv\")):\n",
    "        df = pd.read_csv(filepath)\n",
    "        df['label'] = label  # Class label\n",
    "        data_list.append(df)\n",
    "    return data_list\n",
    "\n",
    "# Load expert and novice data\n",
    "expert_data = load_data(expert_dir, label=\"expert\")\n",
    "novice_data = load_data(novice_dir, label=\"novice\")\n",
    "\n",
    "# Combine lists into a single DataFrame and review the structure\n",
    "all_data = expert_data + novice_data\n",
    "print(\"Expert and novice data loaded.\")\n",
    "print(f\"Total time series: {len(all_data)}\")\n",
    "print(\"Data example:\", all_data[0].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c484cf3a-97cb-4990-88b3-d12e14161ed5",
   "metadata": {},
   "source": [
    "# Converting Timestamp to Relative Time in Milliseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a890927-d086-490d-b6dd-344cd6471425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after converting Timestamp to relative time:\n",
      "   PositionX  PositionY  PositionZ  RotationX  RotationY  RotationZ  \\\n",
      "0   0.066467  -0.148628   0.171193   0.126154   0.984342  -0.056134   \n",
      "1   0.099649  -0.153283   0.165442   0.031201   0.998373  -0.041187   \n",
      "2   0.099649  -0.153283   0.165442   0.031201   0.998373  -0.041187   \n",
      "3   0.099649  -0.153283   0.165442   0.031201   0.998373  -0.041187   \n",
      "4   0.099225  -0.153320   0.165391   0.032077   0.998298  -0.041397   \n",
      "\n",
      "   RotationW   label  time  \n",
      "0  -0.109569  expert   0.0  \n",
      "1  -0.024101  expert   9.0  \n",
      "2  -0.024101  expert  15.0  \n",
      "3  -0.024101  expert  20.0  \n",
      "4  -0.025646  expert  63.0  \n"
     ]
    }
   ],
   "source": [
    "# Function to convert timestamp to relative time in milliseconds\n",
    "def convert_to_relative_time(df):\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    df['time'] = (df['Timestamp'] - df['Timestamp'].iloc[0]).dt.total_seconds() * 1000  # Milliseconds\n",
    "    return df.drop(columns=['Timestamp'])  # Remove original column\n",
    "\n",
    "# Apply the function to each series in the list\n",
    "all_data = [convert_to_relative_time(df) for df in all_data]\n",
    "\n",
    "# Review the structure of the data\n",
    "print(\"Data after converting Timestamp to relative time:\")\n",
    "print(all_data[0].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea12460e-6d83-411c-9bef-5c2213a04db4",
   "metadata": {},
   "source": [
    "# 3. Interpolation to Match the Length of Time Series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc568a7-1d2b-45fe-969e-a3f2fbffa484",
   "metadata": {},
   "source": [
    "### We calculate the average length of the experts' series and use this length as a reference to interpolate all the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93393eb7-34a1-41fe-a64f-fc95e236c19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after interpolation:\n",
      "         time  PositionX  PositionY  PositionZ  RotationX  RotationY  \\\n",
      "0    0.000000   0.066467  -0.148628   0.171193   0.126154   0.984342   \n",
      "1   91.172662   0.099089  -0.153292   0.165439   0.032355   0.998269   \n",
      "2  182.345324   0.098723  -0.153169   0.165550   0.033184   0.998201   \n",
      "3  273.517986   0.098242  -0.152974   0.165602   0.034438   0.998114   \n",
      "4  364.690647   0.097511  -0.152724   0.165596   0.036225   0.997953   \n",
      "\n",
      "   RotationZ  RotationW   label  \n",
      "0  -0.056134  -0.109569  expert  \n",
      "1  -0.041596  -0.026100  expert  \n",
      "2  -0.041964  -0.027074  expert  \n",
      "3  -0.042095  -0.028392  expert  \n",
      "4  -0.042292  -0.031440  expert  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "import pandas as pd\n",
    "\n",
    "# Calculate the average length of the expert series\n",
    "mean_length = int(np.mean([len(df) for df in expert_data]))\n",
    "\n",
    "# Function to interpolate to a standard length\n",
    "def interpolate_series(df, target_length):\n",
    "    interpolated_df = pd.DataFrame()\n",
    "    common_time = np.linspace(0, df['time'].iloc[-1], target_length)\n",
    "    interpolated_df['time'] = common_time\n",
    "    for col in df.columns:\n",
    "        if col != 'time' and col != 'label':  # Exclude the label\n",
    "            f = interp1d(df['time'], df[col], kind='linear', fill_value=\"extrapolate\")\n",
    "            interpolated_df[col] = f(common_time)\n",
    "    interpolated_df['label'] = df['label'].iloc[0]  # Keep the original label\n",
    "    return interpolated_df\n",
    "\n",
    "# Apply interpolation to all series\n",
    "all_data_interpolated = [interpolate_series(df, mean_length) for df in all_data]\n",
    "\n",
    "# Review the structure after interpolation\n",
    "print(\"Data after interpolation:\")\n",
    "print(all_data_interpolated[0].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c133c19-7351-4b4c-a8bd-ff7bb6ec78c4",
   "metadata": {},
   "source": [
    "# 4. Preparing Data for Training (Concatenation and Division of Variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3f11a9-94b1-4c96-a723-3df1e5e033cf",
   "metadata": {},
   "source": [
    "### We concatenate all the interpolated series and split into features (X) and labels (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "608b3a8c-ceea-4e52-98a9-749a7d16fe80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prepared for classification:\n",
      "Features (X): (3906, 7)\n",
      "Labels (y): (3906,)\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all series into a single DataFrame\n",
    "data_for_classification = pd.concat(all_data_interpolated, ignore_index=True)\n",
    "\n",
    "# Separate features and labels\n",
    "X = data_for_classification.drop(columns=['label', 'time'])  # Features (without label or time)\n",
    "y = data_for_classification['label']  # Labels\n",
    "\n",
    "print(\"Data prepared for classification:\")\n",
    "print(\"Features (X):\", X.shape)\n",
    "print(\"Labels (y):\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bc2925-4e68-4ad2-b633-25b806a3aee8",
   "metadata": {},
   "source": [
    "# 5. Training and Evaluation with Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9123d297-a49a-4b36-bf34-3c6ea23b3978",
   "metadata": {},
   "source": [
    "### Here we will use train_test_split to split the dataset and test a RandomForestClassifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42549028-83bb-46ab-9510-1cb9c0b0c954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.9991467576791809\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      expert       1.00      1.00      1.00       837\n",
      "      novice       1.00      1.00      1.00       335\n",
      "\n",
      "    accuracy                           1.00      1172\n",
      "   macro avg       1.00      1.00      1.00      1172\n",
      "weighted avg       1.00      1.00      1.00      1172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate performance\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Model accuracy:\", accuracy)\n",
    "print(\"Classification report:\\n\", report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680d2f6a-8202-4083-8c13-ee92562ddcce",
   "metadata": {},
   "source": [
    "# 6. Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf5f00fd-0ad0-464b-9101-983d91d40968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at ./models/random_forest_model.joblib\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Path to save the trained model\n",
    "model_filename = './models/random_forest_model.joblib'\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, model_filename)\n",
    "print(f\"Model saved at {model_filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ab26ae4-f5a8-4c32-965a-113c203726df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "loaded_model = joblib.load(model_filename)\n",
    "print(\"Model loaded successfully.\")\n",
    "\n",
    "# Classification function for new time series\n",
    "def classify_series(new_series, model, target_length):\n",
    "    # Convert Timestamp to relative time in milliseconds\n",
    "    new_series = convert_to_relative_time(new_series)\n",
    "    # Interpolate the series to the same number of points as the model\n",
    "    interpolated_series = interpolate_series(new_series, target_length)\n",
    "    # Extract features (excluding 'time' and 'label' columns if present)\n",
    "    X_new = interpolated_series.drop(columns=['time'], errors='ignore')\n",
    "    # Classify with the loaded model\n",
    "    prediction = model.predict(X_new)\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "033ef96b-79d1-4562-8d1c-41a4b921201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to interpolate to a standard length\n",
    "def interpolate_series(df, target_length):\n",
    "    interpolated_df = pd.DataFrame()\n",
    "    common_time = np.linspace(0, df['time'].iloc[-1], target_length)\n",
    "    interpolated_df['time'] = common_time\n",
    "    for col in df.columns:\n",
    "        if col != 'time' and col != 'label':  # Exclude label if present\n",
    "            f = interp1d(df['time'], df[col], kind='linear', fill_value=\"extrapolate\")\n",
    "            interpolated_df[col] = f(common_time)\n",
    "    # Only add 'label' if it exists in the original DataFrame\n",
    "    if 'label' in df.columns:\n",
    "        interpolated_df['label'] = df['label'].iloc[0]\n",
    "    return interpolated_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c8a06a9-de09-4d04-b979-4f661888f70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification of the series in ./trajectories/test_serie/positions01.csv: novice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mauricioherrera/opt/anaconda3/envs/Secma/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Classification function for a complete series (simplified to return a single prediction)\n",
    "def classify_series(new_series, model, target_length):\n",
    "    # Convert Timestamp to relative time in milliseconds\n",
    "    new_series = convert_to_relative_time(new_series)\n",
    "    # Interpolate the series to the same number of points as the model\n",
    "    interpolated_series = interpolate_series(new_series, target_length)\n",
    "    \n",
    "    # Select only the first record for classification\n",
    "    X_new = interpolated_series.drop(columns=['time'], errors='ignore').iloc[0].values.reshape(1, -1)\n",
    "    \n",
    "    # Classify with the loaded model\n",
    "    prediction = model.predict(X_new)\n",
    "    return prediction[0]  # Return a single label\n",
    "\n",
    "# Path to the directory with .csv files\n",
    "csv_directory = './trajectories/test_serie/'\n",
    "\n",
    "# Load and classify each .csv file in the directory\n",
    "for csv_file in glob.glob(f\"{csv_directory}/*.csv\"):\n",
    "    new_series_df = pd.read_csv(csv_file)\n",
    "    result = classify_series(new_series_df, loaded_model, mean_length)\n",
    "    print(f\"Classification of the series in {csv_file}:\", result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52a02fdc-1e68-4913-80ad-3cd44c08caa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at ./models/random_forest_model.joblib\n"
     ]
    }
   ],
   "source": [
    "# Function to extract summary statistics from each series in the dataset\n",
    "def extract_features(data_list):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for df in data_list:\n",
    "        feature_vector = []\n",
    "        for col in df.columns:\n",
    "            if col != 'time' and col != 'label':  # Exclude 'time' and 'label'\n",
    "                feature_vector.extend([\n",
    "                    df[col].mean(),\n",
    "                    df[col].std(),\n",
    "                    df[col].min(),\n",
    "                    df[col].max(),\n",
    "                    df[col].median(),\n",
    "                ])\n",
    "        features.append(feature_vector)\n",
    "        labels.append(df['label'].iloc[0])  # Get the label for the entire series\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Extract features and labels from the training dataset\n",
    "X_train, y_train = extract_features(all_data_interpolated)\n",
    "\n",
    "# Train the model with the summary statistics feature vector\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model\n",
    "import joblib\n",
    "model_filename = './models/random_forest_model.joblib'  # Define the model file path\n",
    "joblib.dump(model, model_filename)\n",
    "print(f\"Model saved at {model_filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dbe07a-b3d3-4069-8535-3adfd0e8cac3",
   "metadata": {},
   "source": [
    "# Giving a grade to the user's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa691cc7-eeb4-4e3b-87c1-3270df049966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at ./models/random_forest_model.joblib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "\n",
    "# Function to extract summary statistics from each series in the dataset\n",
    "def extract_features(data_list):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for df in data_list:\n",
    "        feature_vector = []\n",
    "        for col in df.columns:\n",
    "            if col != 'time' and col != 'label':  # Exclude 'time' and 'label'\n",
    "                feature_vector.extend([\n",
    "                    df[col].mean(),\n",
    "                    df[col].std(),\n",
    "                    df[col].min(),\n",
    "                    df[col].max(),\n",
    "                    df[col].median(),\n",
    "                ])\n",
    "        features.append(feature_vector)\n",
    "        labels.append(df['label'].iloc[0])  # Get the label for the entire series\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Assuming `all_data_interpolated` is a list of interpolated DataFrames\n",
    "X_train, y_train = extract_features(all_data_interpolated)\n",
    "\n",
    "# Train the model with summary statistics\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "model_filename = './models/random_forest_model.joblib'\n",
    "joblib.dump(model, model_filename)\n",
    "print(f\"Model saved at {model_filename}\")\n",
    "\n",
    "# Classification function with a score scale based on probability\n",
    "def classify_series_with_score(new_series, model, target_length):\n",
    "    # Convert Timestamp to relative time in milliseconds\n",
    "    new_series = convert_to_relative_time(new_series)\n",
    "    # Interpolate the series to the same number of points as the model\n",
    "    interpolated_series = interpolate_series(new_series, target_length)\n",
    "    \n",
    "    # Calculate summary statistics to reduce the series to a single feature vector\n",
    "    feature_vector = []\n",
    "    for col in interpolated_series.columns:\n",
    "        if col != 'time' and col != 'label':  # Exclude 'time' and 'label'\n",
    "            feature_vector.extend([\n",
    "                interpolated_series[col].mean(),\n",
    "                interpolated_series[col].std(),\n",
    "                interpolated_series[col].min(),\n",
    "                interpolated_series[col].max(),\n",
    "                interpolated_series[col].median(),\n",
    "            ])\n",
    "    \n",
    "    # Ensure the feature vector has the correct format\n",
    "    X_new = np.array(feature_vector).reshape(1, -1)\n",
    "    \n",
    "    # Get the probability of belonging to the \"expert\" class\n",
    "    proba = model.predict_proba(X_new)[0]\n",
    "    proba_expert = proba[0]  # Assuming index 0 is \"expert\" and index 1 is \"novice\"\n",
    "    \n",
    "    # Convert the probability to a 1 to 7 scale\n",
    "    if proba_expert >= 0.85:\n",
    "        score = 7\n",
    "    elif proba_expert >= 0.70:\n",
    "        score = 6\n",
    "    elif proba_expert >= 0.55:\n",
    "        score = 5\n",
    "    elif proba_expert >= 0.40:\n",
    "        score = 4\n",
    "    elif proba_expert >= 0.25:\n",
    "        score = 3\n",
    "    elif proba_expert >= 0.10:\n",
    "        score = 2\n",
    "    else:\n",
    "        score = 1\n",
    "\n",
    "    # Assign a label based on the score\n",
    "    if score >= 6.0:\n",
    "        label = \"expert\"\n",
    "    elif score >= 4.0:\n",
    "        label = \"intermediate\"\n",
    "    else:\n",
    "        label = \"novice\"\n",
    "    \n",
    "    return label, score, proba_expert\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d45d906-600d-4044-ae3c-489a46f52ba6",
   "metadata": {},
   "source": [
    "### Next, and as an example, we consider three users who generate the records: novice -> positions01.csv, expert-> positions08.csv, expert-> positions02.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a058bf9-515a-4cc9-8088-75bd9fe7b826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification for ./trajectories/test_serie/positions08.csv:\n",
      "Label: expert\n",
      "Score on a scale of 1 to 7: 7\n",
      "Probability of being an expert: 0.94\n",
      "\n",
      "Classification for ./trajectories/test_serie/positions01.csv:\n",
      "Label: novice\n",
      "Score on a scale of 1 to 7: 2\n",
      "Probability of being an expert: 0.15\n",
      "\n",
      "Classification for ./trajectories/test_serie/positions02.csv:\n",
      "Label: expert\n",
      "Score on a scale of 1 to 7: 7\n",
      "Probability of being an expert: 0.96\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Directory with .csv files\n",
    "csv_directory = './trajectories/test_serie/'\n",
    "\n",
    "# Load and classify each .csv file in the directory\n",
    "for csv_file in glob.glob(f\"{csv_directory}/*.csv\"):\n",
    "    new_series_df = pd.read_csv(csv_file)\n",
    "    label, score, proba_expert = classify_series_with_score(new_series_df, model, mean_length)\n",
    "    print(f\"Classification for {csv_file}:\")\n",
    "    print(f\"Label: {label}\")\n",
    "    print(f\"Score on a scale of 1 to 7: {score}\")\n",
    "    print(f\"Probability of being an expert: {proba_expert:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f351e29-9122-4b7b-b8c2-a7a7069ec4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
